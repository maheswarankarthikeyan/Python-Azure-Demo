{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí∞ Lab 9: Cost Optimization\n",
    "## Module 9 - Managing Azure OpenAI Costs\n",
    "\n",
    "**Duration:** 10 minutes\n",
    "\n",
    "**Objectives:**\n",
    "- Implement intelligent model routing\n",
    "- Use Batch API for non-urgent tasks\n",
    "- Monitor token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "DEMO_MODE = False\n",
    "client = None\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MODEL_MINI = \"gpt-4o-mini\"  # Optional: add AZURE_OPENAI_DEPLOYMENT_MINI secret\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
    "    AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
    "    try: MODEL_NAME = userdata.get('AZURE_OPENAI_DEPLOYMENT')\n",
    "    except: pass\n",
    "    try: MODEL_MINI = userdata.get('AZURE_OPENAI_DEPLOYMENT_MINI')\n",
    "    except: MODEL_MINI = MODEL_NAME  # Fall back to main model if mini not available\n",
    "    if AZURE_OPENAI_KEY and AZURE_OPENAI_ENDPOINT:\n",
    "        if not AZURE_OPENAI_ENDPOINT.startswith('http'):\n",
    "            AZURE_OPENAI_ENDPOINT = 'https://' + AZURE_OPENAI_ENDPOINT\n",
    "        print(f\"‚úÖ Loaded. Main: {MODEL_NAME}, Mini: {MODEL_MINI}\")\n",
    "        if MODEL_NAME == MODEL_MINI:\n",
    "            print(\"   (Using same model for both - add AZURE_OPENAI_DEPLOYMENT_MINI for cost routing)\")\n",
    "    else: raise ValueError()\n",
    "except: print(\"‚ö†Ô∏è DEMO MODE\"); DEMO_MODE = True\n",
    "\n",
    "if not DEMO_MODE:\n",
    "    from openai import AzureOpenAI\n",
    "    client = AzureOpenAI(api_key=AZURE_OPENAI_KEY, api_version=\"2024-06-01\", azure_endpoint=AZURE_OPENAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI Pricing\n",
    "\n",
    "| Model | Input/1M | Output/1M | Best For |\n",
    "|-------|----------|-----------|----------|\n",
    "| GPT-4o | $5.00 | $15.00 | Complex reasoning |\n",
    "| GPT-4o-mini | $0.15 | $0.60 | Simple tasks |\n",
    "| Batch API | 50% off | 50% off | Non-urgent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Intelligent Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostOptimizedRouter:\n",
    "    PRICING = {\"gpt-4o\": {\"input\": 5.0, \"output\": 15.0}, \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.60}}\n",
    "    SIMPLE = [\"balance\", \"hours\", \"location\", \"hello\", \"status\"]\n",
    "    COMPLEX = [\"fraud\", \"investigate\", \"analyze\", \"recommend\", \"should i\"]\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.usage_log = []\n",
    "    \n",
    "    def select_model(self, query):\n",
    "        q = query.lower()\n",
    "        if any(p in q for p in self.COMPLEX): return MODEL_NAME\n",
    "        return MODEL_MINI if not DEMO_MODE else MODEL_NAME\n",
    "    \n",
    "    def invoke(self, query):\n",
    "        model = self.select_model(query)\n",
    "        \n",
    "        if DEMO_MODE or not self.client:\n",
    "            cost = 0.0001 if \"mini\" in model else 0.001\n",
    "            self.usage_log.append({\"model\": model, \"tokens\": 100, \"cost\": cost})\n",
    "            return {\"response\": f\"Response to: {query[:30]}... [DEMO]\", \"model\": model, \"cost\": cost}\n",
    "        \n",
    "        response = self.client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": query}])\n",
    "        usage = response.usage\n",
    "        pricing = self.PRICING.get(model, self.PRICING[\"gpt-4o\"])\n",
    "        cost = (usage.prompt_tokens * pricing[\"input\"] + usage.completion_tokens * pricing[\"output\"]) / 1_000_000\n",
    "        \n",
    "        self.usage_log.append({\"model\": model, \"tokens\": usage.total_tokens, \"cost\": cost})\n",
    "        return {\"response\": response.choices[0].message.content, \"model\": model, \"tokens\": usage.total_tokens, \"cost\": cost}\n",
    "\n",
    "router = CostOptimizedRouter(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What's my account balance?\",\n",
    "    \"Investigate this suspicious transaction pattern\",\n",
    "    \"What are your branch hours?\",\n",
    "    \"Should I refinance my mortgage?\"\n",
    "]\n",
    "\n",
    "print(\"Cost-Optimized Routing\")\n",
    "print(\"=\"*50)\n",
    "for q in queries:\n",
    "    r = router.invoke(q)\n",
    "    print(f\"\\n{q[:40]}...\")\n",
    "    print(f\"  Model: {r['model']} | Cost: ${r['cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Batch API (50% Savings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch_request(tasks):\n",
    "    \"\"\"Prepare JSONL for Batch API\"\"\"\n",
    "    lines = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        lines.append(json.dumps({\n",
    "            \"custom_id\": f\"task-{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/chat/completions\",\n",
    "            \"body\": {\"model\": MODEL_NAME, \"messages\": [{\"role\": \"user\", \"content\": task}]}\n",
    "        }))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "batch_tasks = [\n",
    "    \"Summarize account C-001 for compliance\",\n",
    "    \"Summarize account C-002 for compliance\",\n",
    "    \"Summarize account C-003 for compliance\"\n",
    "]\n",
    "\n",
    "print(\"Batch API Request (JSONL):\")\n",
    "print(prepare_batch_request(batch_tasks)[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Cost Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY = 10000\n",
    "TOKENS = 500\n",
    "\n",
    "scenarios = {\n",
    "    \"All GPT-4o\": {\"gpt4o\": 1.0, \"mini\": 0.0, \"batch\": 0.0},\n",
    "    \"Mixed (20/80)\": {\"gpt4o\": 0.2, \"mini\": 0.8, \"batch\": 0.0},\n",
    "    \"Optimized\": {\"gpt4o\": 0.1, \"mini\": 0.6, \"batch\": 0.3}\n",
    "}\n",
    "\n",
    "print(\"Cost Comparison: 10,000 Daily Requests\")\n",
    "print(\"=\"*50)\n",
    "for name, mix in scenarios.items():\n",
    "    gpt4o = DAILY * mix[\"gpt4o\"] * TOKENS * 10 / 1_000_000\n",
    "    mini = DAILY * mix[\"mini\"] * TOKENS * 0.375 / 1_000_000\n",
    "    batch = DAILY * mix[\"batch\"] * TOKENS * 5 / 1_000_000\n",
    "    daily = gpt4o + mini + batch\n",
    "    print(f\"\\n{name}: ${daily:.2f}/day, ${daily*30:.2f}/month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Lab 9 Complete!\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Route simple queries to GPT-4o-mini (97% cheaper)\n",
    "- Use Batch API for non-urgent tasks (50% savings)\n",
    "- Monitor token usage to optimize\n",
    "\n",
    "**Day 2 Labs Complete!**"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}