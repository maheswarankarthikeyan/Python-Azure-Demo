{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Module 4: RAG Fundamentals & Vector Databases\n",
    "\n",
    "**AI Agent Architectures Workshop - Day 1**\n",
    "\n",
    "This notebook covers:\n",
    "- Tokenization and embeddings fundamentals\n",
    "- Azure AI Search for semantic search\n",
    "- Building vector databases with Azure-native tools\n",
    "- Hybrid search (keyword + semantic)\n",
    "\n",
    "**Prerequisites:** Run `00_setup.ipynb` first to configure Azure OpenAI credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai azure-search-documents azure-identity python-dotenv faiss-cpu numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# GOOGLE COLAB SETUP - Add these secrets (click üîë icon):\n",
    "#   - AZURE_OPENAI_KEY: Your API key for chat model\n",
    "#   - AZURE_OPENAI_ENDPOINT: https://xxx.openai.azure.com/ (chat model resource)\n",
    "#   - AZURE_OPENAI_DEPLOYMENT: Your chat model deployment name (e.g., gpt-4o)\n",
    "#\n",
    "# For embeddings (can be same or different resource):\n",
    "#   - AZURE_OPENAI_EMBEDDING: Your embedding deployment name (e.g., text-embedding-3-small)\n",
    "#   - AZURE_OPENAI_EMBEDDING_ENDPOINT: (optional) If embedding is in different resource\n",
    "#   - AZURE_OPENAI_EMBEDDING_KEY: (optional) If embedding is in different resource\n",
    "# =============================================================================\n",
    "\n",
    "DEMO_MODE = False\n",
    "client = None\n",
    "embedding_client = None\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
    "    AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
    "    \n",
    "    # Chat model settings\n",
    "    try:\n",
    "        MODEL_NAME = userdata.get('AZURE_OPENAI_DEPLOYMENT')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Embedding settings - check for separate endpoint/key\n",
    "    try:\n",
    "        EMBEDDING_MODEL = userdata.get('AZURE_OPENAI_EMBEDDING')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check if embedding uses different resource\n",
    "    try:\n",
    "        EMBEDDING_ENDPOINT = userdata.get('AZURE_OPENAI_EMBEDDING_ENDPOINT')\n",
    "        EMBEDDING_KEY = userdata.get('AZURE_OPENAI_EMBEDDING_KEY')\n",
    "    except:\n",
    "        EMBEDDING_ENDPOINT = None\n",
    "        EMBEDDING_KEY = None\n",
    "    \n",
    "    if AZURE_OPENAI_KEY and AZURE_OPENAI_ENDPOINT:\n",
    "        if not AZURE_OPENAI_ENDPOINT.startswith('http'):\n",
    "            AZURE_OPENAI_ENDPOINT = 'https://' + AZURE_OPENAI_ENDPOINT\n",
    "        print(f\"‚úÖ Chat credentials loaded. Model: {MODEL_NAME}\")\n",
    "        print(f\"‚úÖ Embedding model: {EMBEDDING_MODEL}\")\n",
    "        if EMBEDDING_ENDPOINT:\n",
    "            print(f\"   (Using separate embedding endpoint)\")\n",
    "    else:\n",
    "        raise ValueError(\"Missing\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Running in DEMO MODE: {e}\")\n",
    "    DEMO_MODE = True\n",
    "\n",
    "if not DEMO_MODE:\n",
    "    from openai import AzureOpenAI\n",
    "    \n",
    "    # Chat client\n",
    "    client = AzureOpenAI(\n",
    "        api_key=AZURE_OPENAI_KEY,\n",
    "        api_version=\"2024-06-01\",\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    "    )\n",
    "    \n",
    "    # Embedding client - use separate endpoint if provided\n",
    "    if EMBEDDING_ENDPOINT and EMBEDDING_KEY:\n",
    "        if not EMBEDDING_ENDPOINT.startswith('http'):\n",
    "            EMBEDDING_ENDPOINT = 'https://' + EMBEDDING_ENDPOINT\n",
    "        embedding_client = AzureOpenAI(\n",
    "            api_key=EMBEDDING_KEY,\n",
    "            api_version=\"2024-06-01\",\n",
    "            azure_endpoint=EMBEDDING_ENDPOINT\n",
    "        )\n",
    "    else:\n",
    "        embedding_client = client  # Use same client for both\n",
    "    \n",
    "    print(\"‚úÖ Clients ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tiktoken for tokenization analysis\n",
    "!pip install tiktoken --quiet\n",
    "import tiktoken\n",
    "\n",
    "# Get the tokenizer for GPT-4\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Banking text examples\n",
    "texts = [\n",
    "    \"What is my account balance?\",\n",
    "    \"I want to dispute a $500 charge from Amazon on my credit card.\",\n",
    "    \"The customer's SSN is 123-45-6789 and their account number is 9876543210.\"\n",
    "]\n",
    "\n",
    "print(\"=== Tokenization Analysis ===\")\n",
    "for text in texts:\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"\\nText: '{text}'\")\n",
    "    print(f\"Token count: {len(tokens)}\")\n",
    "    print(f\"Tokens: {tokens[:10]}...\" if len(tokens) > 10 else f\"Tokens: {tokens}\")\n",
    "    print(f\"Decoded: {[encoding.decode([t]) for t in tokens[:5]]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Embeddings with Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EMBEDDING SETUP\n",
    "# Uses Azure OpenAI embedding model (text-embedding-3-small recommended)\n",
    "# =============================================================================\n",
    "\n",
    "def get_embedding(text: str) -> list:\n",
    "    \"\"\"Get embedding vector using Azure OpenAI\"\"\"\n",
    "    response = embedding_client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Test embedding\n",
    "test_text = \"How do I check my account balance?\"\n",
    "embedding = get_embedding(test_text)\n",
    "\n",
    "print(f\"Text: '{test_text}'\")\n",
    "print(f\"Embedding model: {EMBEDDING_MODEL}\")\n",
    "print(f\"Embedding dimensions: {len(embedding)}\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")\n",
    "print(f\"Vector magnitude: {np.linalg.norm(embedding):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate semantic similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "# Banking queries - some similar, some different\n",
    "queries = [\n",
    "    \"How do I check my account balance?\",\n",
    "    \"What is my current balance?\",\n",
    "    \"Show me how much money I have\",\n",
    "    \"I want to transfer money to another account\",\n",
    "    \"What are your mortgage rates?\"\n",
    "]\n",
    "\n",
    "# Get embeddings for all queries\n",
    "embeddings = {q: get_embedding(q) for q in queries}\n",
    "\n",
    "# Compare first query to all others\n",
    "base_query = queries[0]\n",
    "print(f\"Base query: '{base_query}'\\n\")\n",
    "print(\"Similarity scores:\")\n",
    "for query in queries[1:]:\n",
    "    similarity = cosine_similarity(embeddings[base_query], embeddings[query])\n",
    "    print(f\"  {similarity:.4f} - '{query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Simple Vector Database with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Sample banking policy documents\n",
    "banking_docs = [\n",
    "    {\n",
    "        \"id\": \"policy_001\",\n",
    "        \"title\": \"Transaction Dispute Policy\",\n",
    "        \"content\": \"Customers can dispute unauthorized transactions within 60 days of the statement date. To initiate a dispute, contact customer service or use the mobile app. Provisional credit may be issued within 10 business days while the investigation is ongoing.\",\n",
    "        \"category\": \"disputes\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"policy_002\",\n",
    "        \"title\": \"Wire Transfer Limits\",\n",
    "        \"content\": \"Daily wire transfer limits are $50,000 for personal accounts and $250,000 for business accounts. International transfers may have additional fees of $25-45. Same-day transfers must be initiated before 4 PM EST.\",\n",
    "        \"category\": \"transfers\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"policy_003\",\n",
    "        \"title\": \"Fraud Protection Policy\",\n",
    "        \"content\": \"Zero liability protection covers unauthorized transactions reported within 2 business days. After 2 days, liability may increase up to $500. We use AI-powered fraud detection to monitor suspicious activity 24/7.\",\n",
    "        \"category\": \"security\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"policy_004\",\n",
    "        \"title\": \"Account Balance Inquiry\",\n",
    "        \"content\": \"Check your account balance anytime through online banking, mobile app, ATM, or by calling customer service. Real-time balance updates are available for all checking and savings accounts.\",\n",
    "        \"category\": \"accounts\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"policy_005\",\n",
    "        \"title\": \"Mortgage Rate Information\",\n",
    "        \"content\": \"Current mortgage rates: 30-year fixed at 6.5%, 15-year fixed at 5.9%, 5/1 ARM at 5.5%. Rates are subject to change daily. Pre-approval is valid for 90 days. Minimum credit score of 620 required.\",\n",
    "        \"category\": \"loans\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(banking_docs)} banking policy documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all documents\n",
    "print(\"Creating embeddings for documents...\")\n",
    "for doc in banking_docs:\n",
    "    doc[\"embedding\"] = get_embedding(doc[\"content\"])\n",
    "    print(f\"  ‚úì {doc['title']}\")\n",
    "\n",
    "# Build FAISS index\n",
    "dimension = len(banking_docs[0][\"embedding\"])\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product (cosine similarity for normalized vectors)\n",
    "\n",
    "# Normalize and add vectors to index\n",
    "vectors = np.array([doc[\"embedding\"] for doc in banking_docs]).astype('float32')\n",
    "faiss.normalize_L2(vectors)  # Normalize for cosine similarity\n",
    "index.add(vectors)\n",
    "\n",
    "print(f\"\\n‚úÖ FAISS index built with {index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query: str, k: int = 3) -> list:\n",
    "    \"\"\"Search for similar documents using FAISS\"\"\"\n",
    "    # Get query embedding\n",
    "    query_embedding = np.array([get_embedding(query)]).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    # Search\n",
    "    scores, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Return results with scores\n",
    "    results = []\n",
    "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "        doc = banking_docs[idx]\n",
    "        results.append({\n",
    "            \"rank\": i + 1,\n",
    "            \"score\": float(score),\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"content\": doc[\"content\"],\n",
    "            \"category\": doc[\"category\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Test search\n",
    "test_queries = [\n",
    "    \"How do I report a fraudulent transaction?\",\n",
    "    \"What are the current mortgage rates?\",\n",
    "    \"Can I send money internationally?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüîç Query: '{query}'\")\n",
    "    results = search_documents(query, k=2)\n",
    "    for r in results:\n",
    "        print(f\"   [{r['score']:.4f}] {r['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(question: str, k: int = 3) -> dict:\n",
    "    \"\"\"Complete RAG pipeline: Retrieve relevant docs and generate answer\"\"\"\n",
    "    \n",
    "    # Step 1: Retrieve relevant documents\n",
    "    retrieved_docs = search_documents(question, k=k)\n",
    "    \n",
    "    # Step 2: Build context from retrieved documents\n",
    "    context_parts = []\n",
    "    for doc in retrieved_docs:\n",
    "        context_parts.append(f\"[{doc['title']}]: {doc['content']}\")\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Step 3: Generate response with context\n",
    "    system_prompt = f\"\"\"You are a helpful banking assistant. Answer the customer's question using ONLY the information provided in the context below. If the answer is not in the context, say \"I don't have information about that in our policies.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Always cite which policy document you're referencing in your answer.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": response.choices[0].message.content,\n",
    "        \"sources\": [doc[\"title\"] for doc in retrieved_docs],\n",
    "        \"retrieval_scores\": [doc[\"score\"] for doc in retrieved_docs]\n",
    "    }\n",
    "\n",
    "# Test RAG pipeline\n",
    "result = rag_query(\"How long do I have to report fraud on my account?\")\n",
    "\n",
    "print(f\"‚ùì Question: {result['question']}\")\n",
    "print(f\"\\nüí¨ Answer: {result['answer']}\")\n",
    "print(f\"\\nüìö Sources: {', '.join(result['sources'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple banking questions\n",
    "banking_questions = [\n",
    "    \"What is the daily limit for wire transfers?\",\n",
    "    \"How can I check my account balance?\",\n",
    "    \"What credit score do I need for a mortgage?\",\n",
    "    \"How do I dispute a charge on my credit card?\"\n",
    "]\n",
    "\n",
    "print(\"=== Banking RAG Q&A ===\")\n",
    "for question in banking_questions:\n",
    "    result = rag_query(question)\n",
    "    print(f\"\\n‚ùì {question}\")\n",
    "    print(f\"üí¨ {result['answer'][:200]}...\" if len(result['answer']) > 200 else f\"üí¨ {result['answer']}\")\n",
    "    print(f\"üìö Sources: {', '.join(result['sources'][:2])}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chunking Strategies for Banking Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_document(text: str, chunk_size: int = 500, overlap: int = 50) -> list:\n",
    "    \"\"\"Split document into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append({\n",
    "            \"text\": chunk,\n",
    "            \"start\": start,\n",
    "            \"end\": min(end, len(text))\n",
    "        })\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# Example: Long banking document\n",
    "long_document = \"\"\"\n",
    "MORTGAGE APPLICATION REQUIREMENTS\n",
    "\n",
    "Section 1: Income Verification\n",
    "Applicants must provide proof of income for the past two years. Acceptable documents include W-2 forms, tax returns, and pay stubs from the last 30 days. Self-employed applicants must provide business tax returns and profit/loss statements.\n",
    "\n",
    "Section 2: Credit Requirements\n",
    "A minimum credit score of 620 is required for conventional loans. FHA loans may accept scores as low as 580 with a 3.5% down payment. Higher credit scores qualify for better interest rates.\n",
    "\n",
    "Section 3: Down Payment\n",
    "Conventional loans require a minimum 3% down payment for first-time buyers. A 20% down payment eliminates the need for private mortgage insurance (PMI). Gift funds are acceptable with proper documentation.\n",
    "\n",
    "Section 4: Property Requirements\n",
    "The property must be appraised by a licensed appraiser. The appraisal must meet or exceed the purchase price. Properties must meet minimum safety and habitability standards.\n",
    "\"\"\"\n",
    "\n",
    "chunks = chunk_document(long_document, chunk_size=300, overlap=50)\n",
    "print(f\"Document split into {len(chunks)} chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} (chars {chunk['start']}-{chunk['end']}):\")\n",
    "    print(f\"  '{chunk['text'][:100]}...'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercise: Build Your Own Banking RAG\n",
    "\n",
    "**Task:** Extend the RAG system to:\n",
    "1. Add metadata filtering (e.g., only search \"security\" category documents)\n",
    "2. Implement hybrid search (combine keyword and semantic search)\n",
    "3. Add source citations to the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Implement filtered RAG search\n",
    "def filtered_rag_query(question: str, category_filter: str = None, k: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Implement RAG with category filtering\n",
    "    \n",
    "    1. Filter documents by category before search\n",
    "    2. Search only filtered documents\n",
    "    3. Generate response with filtered context\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# result = filtered_rag_query(\"How do I report fraud?\", category_filter=\"security\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéÅ BONUS: Production Azure AI Search Integration\n",
    "\n",
    "This section shows how to use **Azure AI Search** for production-grade vector search with:\n",
    "- Hybrid search (keyword + semantic + vector)\n",
    "- Scalable indexing\n",
    "- Built-in security and compliance\n",
    "\n",
    "**Prerequisites:** Azure subscription and Azure AI Search service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AZURE CLI: Create Azure AI Search Service\n",
    "# =============================================================================\n",
    "# Run these commands in Azure Cloud Shell or local terminal with Azure CLI\n",
    "#\n",
    "# # Set variables\n",
    "# RESOURCE_GROUP=\"rg-ai-workshop\"\n",
    "# LOCATION=\"eastus\"\n",
    "# SEARCH_SERVICE=\"search-banking-workshop\"  # Must be globally unique\n",
    "#\n",
    "# # Create resource group (if not exists)\n",
    "# az group create --name $RESOURCE_GROUP --location $LOCATION\n",
    "#\n",
    "# # Create Azure AI Search (Free tier for testing)\n",
    "# az search service create \\\n",
    "#     --name $SEARCH_SERVICE \\\n",
    "#     --resource-group $RESOURCE_GROUP \\\n",
    "#     --location $LOCATION \\\n",
    "#     --sku free\n",
    "#\n",
    "# # Get the admin key\n",
    "# az search admin-key show \\\n",
    "#     --service-name $SEARCH_SERVICE \\\n",
    "#     --resource-group $RESOURCE_GROUP\n",
    "#\n",
    "# # Get the endpoint\n",
    "# echo \"Endpoint: https://${SEARCH_SERVICE}.search.windows.net\"\n",
    "#\n",
    "# =============================================================================\n",
    "# COST ESTIMATES:\n",
    "# - Free tier: 50 MB storage, 3 indexes (good for testing)\n",
    "# - Basic tier: ~$75/month, 2 GB storage, 15 indexes\n",
    "# - Standard S1: ~$250/month, 25 GB storage, 50 indexes\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Azure CLI commands ready - run in terminal to create Azure AI Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Azure AI Search Client Setup\n",
    "# Add these secrets to Google Colab (click üîë icon):\n",
    "#   - AZURE_SEARCH_ENDPOINT: https://your-search.search.windows.net\n",
    "#   - AZURE_SEARCH_KEY: Your admin key\n",
    "# =============================================================================\n",
    "\n",
    "SEARCH_ENABLED = False\n",
    "search_client = None\n",
    "index_client = None\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    AZURE_SEARCH_ENDPOINT = userdata.get('AZURE_SEARCH_ENDPOINT')\n",
    "    AZURE_SEARCH_KEY = userdata.get('AZURE_SEARCH_KEY')\n",
    "    \n",
    "    if AZURE_SEARCH_ENDPOINT and AZURE_SEARCH_KEY:\n",
    "        from azure.search.documents import SearchClient\n",
    "        from azure.search.documents.indexes import SearchIndexClient\n",
    "        from azure.core.credentials import AzureKeyCredential\n",
    "        \n",
    "        credential = AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    "        index_client = SearchIndexClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=credential)\n",
    "        SEARCH_ENABLED = True\n",
    "        print(f\"‚úÖ Azure AI Search connected: {AZURE_SEARCH_ENDPOINT}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Azure AI Search credentials not found - skipping\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Azure AI Search not configured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Create Search Index with Vector Field\n",
    "# =============================================================================\n",
    "\n",
    "if SEARCH_ENABLED:\n",
    "    from azure.search.documents.indexes.models import (\n",
    "        SearchIndex,\n",
    "        SearchField,\n",
    "        SearchFieldDataType,\n",
    "        VectorSearch,\n",
    "        HnswAlgorithmConfiguration,\n",
    "        VectorSearchProfile,\n",
    "        SemanticConfiguration,\n",
    "        SemanticField,\n",
    "        SemanticPrioritizedFields,\n",
    "        SemanticSearch\n",
    "    )\n",
    "    \n",
    "    INDEX_NAME = \"banking-policies-workshop\"\n",
    "    \n",
    "    # Define fields\n",
    "    fields = [\n",
    "        SearchField(name=\"id\", type=SearchFieldDataType.String, key=True, filterable=True),\n",
    "        SearchField(name=\"title\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"category\", type=SearchFieldDataType.String, filterable=True, facetable=True),\n",
    "        SearchField(\n",
    "            name=\"embedding\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=1536,\n",
    "            vector_search_profile_name=\"vector-profile\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Vector search configuration\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"hnsw-config\")],\n",
    "        profiles=[VectorSearchProfile(name=\"vector-profile\", algorithm_configuration_name=\"hnsw-config\")]\n",
    "    )\n",
    "    \n",
    "    # Semantic search configuration\n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            content_fields=[SemanticField(field_name=\"content\")]\n",
    "        )\n",
    "    )\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "    \n",
    "    # Create index\n",
    "    index = SearchIndex(\n",
    "        name=INDEX_NAME,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "        semantic_search=semantic_search\n",
    "    )\n",
    "    \n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f\"‚úÖ Created index: {result.name}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping - Azure AI Search not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Upload Documents to Azure AI Search\n",
    "# =============================================================================\n",
    "\n",
    "if SEARCH_ENABLED:\n",
    "    from azure.search.documents import SearchClient\n",
    "    \n",
    "    search_client = SearchClient(\n",
    "        endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        index_name=INDEX_NAME,\n",
    "        credential=credential\n",
    "    )\n",
    "    \n",
    "    # Prepare documents with embeddings (reuse from earlier)\n",
    "    docs_to_upload = []\n",
    "    for doc in banking_docs:\n",
    "        docs_to_upload.append({\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"content\": doc[\"content\"],\n",
    "            \"category\": doc[\"category\"],\n",
    "            \"embedding\": doc[\"embedding\"]\n",
    "        })\n",
    "    \n",
    "    # Upload\n",
    "    result = search_client.upload_documents(documents=docs_to_upload)\n",
    "    print(f\"‚úÖ Uploaded {len(docs_to_upload)} documents\")\n",
    "    print(f\"   Succeeded: {sum(1 for r in result if r.succeeded)}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping - Azure AI Search not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Hybrid Search: Vector + Keyword + Semantic\n",
    "# =============================================================================\n",
    "\n",
    "if SEARCH_ENABLED:\n",
    "    from azure.search.documents.models import VectorizedQuery\n",
    "    \n",
    "    def azure_hybrid_search(query: str, k: int = 3) -> list:\n",
    "        \"\"\"Perform hybrid search combining vector, keyword, and semantic ranking\"\"\"\n",
    "        \n",
    "        # Get query embedding\n",
    "        query_embedding = get_embedding(query)\n",
    "        \n",
    "        # Vector query\n",
    "        vector_query = VectorizedQuery(\n",
    "            vector=query_embedding,\n",
    "            k_nearest_neighbors=k,\n",
    "            fields=\"embedding\"\n",
    "        )\n",
    "        \n",
    "        # Hybrid search with semantic ranking\n",
    "        results = search_client.search(\n",
    "            search_text=query,  # Keyword search\n",
    "            vector_queries=[vector_query],  # Vector search\n",
    "            query_type=\"semantic\",  # Semantic ranking\n",
    "            semantic_configuration_name=\"semantic-config\",\n",
    "            top=k,\n",
    "            select=[\"id\", \"title\", \"content\", \"category\"]\n",
    "        )\n",
    "        \n",
    "        return [{\"title\": r[\"title\"], \"content\": r[\"content\"], \"score\": r[\"@search.score\"]} for r in results]\n",
    "    \n",
    "    # Test hybrid search\n",
    "    test_query = \"How do I report fraudulent activity on my account?\"\n",
    "    print(f\"üîç Query: '{test_query}'\\n\")\n",
    "    \n",
    "    results = azure_hybrid_search(test_query)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['score']:.4f}] {r['title']}\")\n",
    "        print(f\"   {r['content'][:100]}...\\n\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping - Azure AI Search not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Production RAG with Azure AI Search\n",
    "# =============================================================================\n",
    "\n",
    "if SEARCH_ENABLED and not DEMO_MODE:\n",
    "    def azure_rag_query(question: str, k: int = 3) -> dict:\n",
    "        \"\"\"Production RAG using Azure AI Search\"\"\"\n",
    "        \n",
    "        # Retrieve with hybrid search\n",
    "        retrieved = azure_hybrid_search(question, k=k)\n",
    "        \n",
    "        # Build context\n",
    "        context = \"\\n\\n\".join([f\"[{r['title']}]: {r['content']}\" for r in retrieved])\n",
    "        \n",
    "        # Generate response\n",
    "        system_prompt = f\"\"\"You are a banking assistant. Answer using ONLY the context below.\n",
    "If the answer isn't in the context, say so. Cite your sources.\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"sources\": [r[\"title\"] for r in retrieved]\n",
    "        }\n",
    "    \n",
    "    # Test production RAG\n",
    "    result = azure_rag_query(\"What are the wire transfer limits?\")\n",
    "    print(f\"‚ùì {result['question']}\")\n",
    "    print(f\"\\nüí¨ {result['answer']}\")\n",
    "    print(f\"\\nüìö Sources: {', '.join(result['sources'])}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping - requires both Azure AI Search and Azure OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cleanup (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "# Uncomment to delete the index when done\n",
    "# if SEARCH_ENABLED:\n",
    "#     index_client.delete_index(INDEX_NAME)\n",
    "#     print(f\"üóëÔ∏è Deleted index: {INDEX_NAME}\")\n",
    "\n",
    "# Azure CLI to delete the search service:\n",
    "# az search service delete --name $SEARCH_SERVICE --resource-group $RESOURCE_GROUP --yes\n",
    "\n",
    "print(\"Cleanup commands ready - uncomment to delete resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS vs Azure AI Search Comparison\n",
    "\n",
    "| Feature | FAISS (In-Memory) | Azure AI Search |\n",
    "|---------|-------------------|------------------|\n",
    "| **Setup** | `pip install faiss-cpu` | Azure subscription required |\n",
    "| **Cost** | Free | Free tier available, ~$75+/month for production |\n",
    "| **Persistence** | None (in-memory) | Fully managed, durable |\n",
    "| **Scale** | Single machine | Distributed, auto-scaling |\n",
    "| **Search Types** | Vector only | Hybrid (vector + keyword + semantic) |\n",
    "| **Security** | None built-in | RBAC, private endpoints, encryption |\n",
    "| **Best For** | Prototyping, small datasets | Production, enterprise apps |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "1. **Tokenization**: How text is split into tokens for LLM processing\n",
    "2. **Embeddings**: Converting text to dense vectors for semantic similarity\n",
    "3. **Vector Databases**: Using FAISS for efficient similarity search\n",
    "4. **RAG Pipeline**: Retrieve ‚Üí Context ‚Üí Generate workflow\n",
    "5. **Azure AI Search**: Production-ready vector search with hybrid capabilities\n",
    "6. **Chunking**: Strategies for splitting long documents\n",
    "\n",
    "**Key Takeaways for Banking:**\n",
    "- RAG keeps knowledge current without retraining\n",
    "- Source citations are essential for compliance\n",
    "- Hybrid search (keyword + semantic) works best for banking queries\n",
    "- Use metadata filtering for account-type-specific policies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
