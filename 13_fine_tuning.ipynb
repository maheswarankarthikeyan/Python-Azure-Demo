{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Lab 13: Fine-Tuning Models\n",
    "## Module 13 - Azure OpenAI Fine-Tuning with LoRA\n",
    "\n",
    "**Duration:** 30 minutes\n",
    "\n",
    "**Objectives:**\n",
    "- Prepare training data in JSONL format\n",
    "- Fine-tune GPT-4o-mini for JSON output\n",
    "- Evaluate fine-tuned model\n",
    "\n",
    "**Banking Scenario:** Fine-tune a loan document extractor\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# =============================================================================\n",
    "# GOOGLE COLAB SETUP - Add these secrets (click üîë icon):\n",
    "#   - AZURE_OPENAI_KEY: Your API key\n",
    "#   - AZURE_OPENAI_ENDPOINT: https://xxx.openai.azure.com/\n",
    "#   - AZURE_OPENAI_DEPLOYMENT: Your model deployment name\n",
    "# =============================================================================\n",
    "\n",
    "DEMO_MODE = False\n",
    "client = None\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
    "    AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
    "    try:\n",
    "        MODEL_NAME = userdata.get('AZURE_OPENAI_DEPLOYMENT')\n",
    "    except:\n",
    "        pass\n",
    "    if AZURE_OPENAI_KEY and AZURE_OPENAI_ENDPOINT:\n",
    "        if not AZURE_OPENAI_ENDPOINT.startswith('http'):\n",
    "            AZURE_OPENAI_ENDPOINT = 'https://' + AZURE_OPENAI_ENDPOINT\n",
    "        print(f\"‚úÖ Credentials loaded. Model: {MODEL_NAME}\")\n",
    "    else:\n",
    "        raise ValueError(\"Missing\")\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Running in DEMO MODE\")\n",
    "    DEMO_MODE = True\n",
    "\n",
    "if not DEMO_MODE:\n",
    "    from openai import AzureOpenAI\n",
    "    client = AzureOpenAI(\n",
    "        api_key=AZURE_OPENAI_KEY,\n",
    "        api_version=\"2024-06-01\",\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    "    )\n",
    "    print(\"‚úÖ Client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training examples for loan extraction\ntraining_examples = [\n    {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"Extract loan details as JSON.\"},\n            {\"role\": \"user\", \"content\": \"Mortgage application for $350,000 at 6.25% fixed rate for 30 years. Applicant income: $95,000. Credit score: 720.\"},\n            {\"role\": \"assistant\", \"content\": '{\"loan_type\": \"mortgage\", \"amount\": 350000, \"rate\": 6.25, \"term_years\": 30, \"income\": 95000, \"credit_score\": 720}'}\n        ]\n    },\n    {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"Extract loan details as JSON.\"},\n            {\"role\": \"user\", \"content\": \"Auto loan request: $25,000 for 60 months at 7.9% APR. Buyer income $55,000, credit 680.\"},\n            {\"role\": \"assistant\", \"content\": '{\"loan_type\": \"auto\", \"amount\": 25000, \"rate\": 7.9, \"term_years\": 5, \"income\": 55000, \"credit_score\": 680}'}\n        ]\n    },\n    {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"Extract loan details as JSON.\"},\n            {\"role\": \"user\", \"content\": \"Personal loan: $15,000 at 12.99% for 3 years. Income: $45,000. Credit: 640.\"},\n            {\"role\": \"assistant\", \"content\": '{\"loan_type\": \"personal\", \"amount\": 15000, \"rate\": 12.99, \"term_years\": 3, \"income\": 45000, \"credit_score\": 640}'}\n        ]\n    }\n]\n\n# Save as JSONL\nwith open(\"training_data.jsonl\", \"w\") as f:\n    for ex in training_examples:\n        f.write(json.dumps(ex) + \"\\n\")\n\nprint(f\"‚úÖ Created training_data.jsonl with {len(training_examples)} examples\")\nprint(\"\\nSample:\")\nprint(json.dumps(training_examples[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Upload and Fine-Tune (Simulated)\n",
    "\n",
    "Note: Actual fine-tuning requires Azure OpenAI fine-tuning access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual code for fine-tuning (requires access)\n\"\"\"\n# Upload training file\nfile = client.files.create(\n    file=open(\"training_data.jsonl\", \"rb\"),\n    purpose=\"fine-tune\"\n)\nprint(f\"File ID: {file.id}\")\n\n# Create fine-tuning job\njob = client.fine_tuning.jobs.create(\n    training_file=file.id,\n    model=\"gpt-4o-mini-2024-07-18\",\n    hyperparameters={\"n_epochs\": 3}\n)\nprint(f\"Job ID: {job.id}\")\n\n# Check status\nstatus = client.fine_tuning.jobs.retrieve(job.id)\nprint(f\"Status: {status.status}\")\n\"\"\"\n\nprint(\"Fine-tuning code ready (requires Azure OpenAI fine-tuning access)\")\nprint(\"\\nCLI equivalent:\")\nprint(\"az openai file upload --file training_data.jsonl --purpose fine-tune\")\nprint(\"az openai fine-tuning job create --model gpt-4o-mini-2024-07-18 --training-file <file-id>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Test Fine-Tuned Model (Simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extraction(model: str, text: str) -> dict:\n    \"\"\"Test loan extraction with a model\"\"\"\n    response = client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Extract loan details as JSON.\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n    return json.loads(response.choices[0].message.content)\n\n# Test with base model\ntest_text = \"Home equity loan for $75,000 at 8.5% for 15 years. Homeowner income $120,000, credit 750.\"\n\nresult = test_extraction(\"gpt-4o-mini\", test_text)\nprint(\"Base model extraction:\")\nprint(json.dumps(result, indent=2))\n\n# With fine-tuned model (when available):\n# result = test_extraction(\"ft:gpt-4o-mini:banking:loan-extractor\", test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extraction(predicted: dict, expected: dict) -> dict:\n    \"\"\"Evaluate extraction accuracy\"\"\"\n    correct = 0\n    total = len(expected)\n    \n    for key, value in expected.items():\n        if key in predicted and predicted[key] == value:\n            correct += 1\n    \n    return {\n        \"accuracy\": correct / total,\n        \"correct_fields\": correct,\n        \"total_fields\": total\n    }\n\n# Test evaluation\nexpected = {\"loan_type\": \"home_equity\", \"amount\": 75000, \"rate\": 8.5, \"term_years\": 15}\npredicted = result\n\neval_result = evaluate_extraction(predicted, expected)\nprint(f\"\\nEvaluation: {eval_result['accuracy']:.0%} accuracy\")\nprint(f\"Correct fields: {eval_result['correct_fields']}/{eval_result['total_fields']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Lab 13 Complete!\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Training data must be in JSONL format\n",
    "- Fine-tuning improves consistency for specific tasks\n",
    "- Always evaluate before deploying\n",
    "- Fine-tuned models cost ~2x base model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
