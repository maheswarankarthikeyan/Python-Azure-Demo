{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution"
      ],
      "metadata": {
        "id": "l4hY3sa_wllC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Version"
      ],
      "metadata": {
        "id": "PDNu3kXonit0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python_version = !python --version\n",
        "print(f'Python Version: {python_version}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yFMosQ5nmbf",
        "outputId": "da76b1f1-62d0-4bb5-9abf-b4133d26fdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: ['Python 3.12.12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XivetmhvrhQm",
        "outputId": "2acbb928-d2b4-45c7-fe9d-2d1e1ffbc807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai~=1.107.0 in /usr/local/lib/python3.12/dist-packages (1.107.3)\n",
            "Requirement already satisfied: google~=2.0.3 in /usr/local/lib/python3.12/dist-packages (2.0.3)\n",
            "Requirement already satisfied: requests~=2.32.4 in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm~=4.67.1 in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging~=25.0 in /usr/local/lib/python3.12/dist-packages (25.0)\n",
            "Requirement already satisfied: typing_extensions~=4.15.0 in /usr/local/lib/python3.12/dist-packages (4.15.0)\n",
            "Requirement already satisfied: pydantic~=2.11.7 in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: google-api-core~=2.25.1 in /usr/local/lib/python3.12/dist-packages (2.25.2)\n",
            "Requirement already satisfied: google-auth~=2.38.0 in /usr/local/lib/python3.12/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core~=2.4.3 in /usr/local/lib/python3.12/dist-packages (2.4.3)\n",
            "Requirement already satisfied: google-cloud-storage~=2.19.0 in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai~=1.107.0) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai~=1.107.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai~=1.107.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai~=1.107.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai~=1.107.0) (1.3.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from google~=2.0.3) (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.4) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.4) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.4) (2025.11.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.7) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core~=2.25.1) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core~=2.25.1) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core~=2.25.1) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.38.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.38.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.38.0) (4.9.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage~=2.19.0) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage~=2.19.0) (1.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai~=1.107.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.107.0) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.38.0) (0.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->google~=2.0.3) (2.8)\n",
            "```json\n",
            "{\n",
            "  \"age\": 35,\n",
            "  \"gender\": \"male\",\n",
            "  \"diagnosis\": \"diabetes\",\n",
            "  \"weight\": 80,\n",
            "  \"smoking\": \"yes\"\n",
            "}\n",
            "```\n",
            "```json\n",
            "{\n",
            "  \"age\": 45,\n",
            "  \"gender\": \"female\",\n",
            "  \"diagnosis\": \"other\",\n",
            "  \"weight\": 0,\n",
            "  \"smoking\": \"no\"\n",
            "}\n",
            "```\n",
            "### About This Item\n",
            "\n",
            "Elevate your gaming experience with the Razer Ornata V3 X gaming keyboard, designed for ultimate performance and comfort. Whether you’re battling it out in your favorite titles or typing up a storm, this keyboard offers a seamless blend of style, functionality, and durability.\n",
            "\n",
            "- **Low-Profile Keys**: Experience a sleek design with responsive keys that enhance your gaming sessions and typing efficiency.\n",
            "- **Spill Resistant**: Play with peace of mind; the durable build protects against accidental spills, ensuring longevity.\n",
            "- **Ergonomic Wrist Rest**: Enjoy extended gaming without fatigue thanks to the comfortable wrist support that promotes better posture.\n",
            "- **Chroma RGB Lighting**: Customize your setup with vibrant backlighting, featuring a spectrum of colors and effects to match your style.\n",
            "- **Silent Membrane Switches**: Engage with quiet keystrokes that provide a satisfying feel without disturbing others around you.\n",
            "- **Cable Routing Options**: Keep your gaming area tidy and organized with versatile cable management options.\n",
            "\n",
            "The Razer Ornata V3 X gaming keyboard combines cutting-edge features with an elegant design, making it the perfect addition to any PC gaming setup. Experience unparalleled comfort and style while dominating your game.\n",
            "### About this item\n",
            "\n",
            "- **Sleek Low-Profile Design**: The Razer Ornata V3 X features low-profile keys that provide a comfortable typing experience while maintaining a modern aesthetic.\n",
            "  \n",
            "- **Enhanced Ergonomics**: Comes with an ergonomic wrist rest that offers support during long gaming sessions, ensuring comfort without compromise.\n",
            "\n",
            "- **Spill Resistant**: Designed with a spill-resistant feature, this keyboard can withstand accidental liquid spills, providing peace of mind during intense gameplay.\n",
            "\n",
            "- **Chroma RGB Lighting**: Customize your gaming setup with Razer’s signature Chroma RGB lighting, allowing you to choose from millions of colors and effects for a truly personalized experience.\n",
            "\n",
            "- **Silent Membrane Switches**: Enjoy quieter key presses with silent membrane switches, perfect for late-night gaming without disturbing others.\n",
            "\n",
            "- **Convenient Cable Routing Options**: Keep your gaming area tidy with integrated cable routing options that help manage your cables effectively.\n",
            "\n",
            "- **Compatibility**: Optimized for PC gaming and fully compatible with Microsoft Windows, making it a versatile choice for gamers.\n",
            "\n",
            "- **Compact Dimensions**: With product dimensions of 17.46 x 5.68 x 1.23 inches and a lightweight design at 2.97 pounds, it fits perfectly on any gaming\n",
            "### About this item\n",
            "\n",
            "Elevate your gaming experience with the Razer Ornata V3 X gaming keyboard, designed for both performance and comfort. This sleek and stylish keyboard combines innovative features with a classic black aesthetic, making it a perfect addition to any gaming setup.\n",
            "\n",
            "- **Low-Profile Keys**: Enjoy a comfortable typing experience with responsive low-profile keys that enhance your gameplay.\n",
            "- **Spill Resistant**: Built to withstand accidental spills, ensuring your keyboard remains functional even in the heat of battle.\n",
            "- **Ergonomic Wrist Rest**: Equipped with a plush wrist rest for added comfort during long gaming sessions, reducing fatigue and strain.\n",
            "- **Chroma RGB Lighting**: Customize your keyboard with vibrant, dynamic RGB lighting effects that sync with your games for an immersive experience.\n",
            "- **Silent Membrane Switches**: Experience quiet and smooth keystrokes, perfect for late-night gaming without disturbing others.\n",
            "- **Cable Routing Options**: Keep your desk organized with multiple cable routing options, allowing for a clean and clutter-free setup.\n",
            "\n",
            "Experience the perfect blend of style, comfort, and functionality with the Razer Ornata V3 X – your ultimate gaming companion.\n",
            "### About this item\n",
            "\n",
            "Elevate your gaming experience with the Razer Ornata V3 X gaming keyboard, designed for both performance and comfort. This sleek and stylish keyboard combines innovative features with a classic black finish, making it the perfect addition to your gaming setup.\n",
            "\n",
            "- **Low-Profile Keys**: Enjoy a comfortable typing experience with keys that are designed for quick response and reduced fatigue during long gaming sessions.\n",
            "- **Spill Resistant**: Play with confidence knowing that accidental spills won't ruin your keyboard, thanks to its durable spill-resistant design.\n",
            "- **Ergonomic Wrist Rest**: Stay comfortable during extended gameplay with a soft wrist rest that provides support and reduces strain.\n",
            "- **Chroma RGB Lighting**: Customize your gaming atmosphere with vibrant, customizable RGB lighting that syncs with your gameplay for an immersive experience.\n",
            "- **Silent Membrane Switches**: Experience quiet yet responsive keystrokes, perfect for late-night gaming without disturbing others.\n",
            "- **Cable Routing Options**: Keep your gaming area tidy with built-in cable routing options that help manage your setup efficiently.\n",
            "\n",
            "With its combination of functionality and style, the Razer Ornata V3 X is the ultimate keyboard for gamers looking to enhance their performance and comfort.\n",
            "### About this item\n",
            "\n",
            "Elevate your gaming experience with the Razer Ornata V3 X gaming keyboard, designed for both performance and comfort. This sleek and stylish keyboard combines innovative features with a classic black finish, making it the perfect addition to your gaming setup.\n",
            "\n",
            "- **Low-Profile Keys**: Enjoy a comfortable typing experience with keys that are designed for quick response and reduced fatigue during long gaming sessions.\n",
            "- **Spill Resistant**: Play with confidence knowing that accidental spills won't ruin your keyboard, thanks to its durable spill-resistant design.\n",
            "- **Ergonomic Wrist Rest**: Stay comfortable during extended gameplay with a soft wrist rest that provides support and reduces strain.\n",
            "- **Chroma RGB Lighting**: Customize your gaming atmosphere with vibrant, customizable RGB lighting that syncs with your gameplay for an immersive experience.\n",
            "- **Silent Membrane Switches**: Experience quiet yet responsive keystrokes, perfect for late-night gaming without disturbing others.\n",
            "- **Cable Routing Options**: Keep your gaming area tidy with built-in cable routing options that help manage your setup efficiently.\n",
            "\n",
            "With its combination of functionality and style, the Razer Ornata V3 X is the ultimate keyboard for gamers looking to enhance their performance and comfort.\n",
            "{'sentiment': 'positive'}\n",
            "{'sentiment': 'positive'}\n",
            "{'sentiment': 'positive'}\n",
            "Let's break down the complaint step by step:\n",
            "\n",
            "1. **phone_model**: The customer explicitly mentions the phone model as \"XUI890\".\n",
            "2. **phone_price**: The customer states the price as 1500 $, but since we need to assume a standard price if unknown, we will use 1000 $ as per the instructions.\n",
            "3. **complaint_desc**: The customer expresses disappointment with the phone, which can be summarized as \"Phone has constant glitches and defects.\"\n",
            "4. **additional_charges**: The customer mentions spending 275 $ to fix the battery, which is the only additional charge provided.\n",
            "5. **refund_expected**: The customer explicitly mentions \"refund\", indicating they are expecting a refund.\n",
            "\n",
            "Now, I will compile this information into the required JSON format:\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"phone_model\": \"XUI890\",\n",
            "    \"phone_price\": 1000,\n",
            "    \"complaint_desc\": \"Phone has constant glitches and defects.\",\n",
            "    \"additional_charges\": 275,\n",
            "    \"refund_expected\": true\n",
            "}\n",
            "```\n",
            "1. **Main Sentiment**: Negative\n",
            "2. **Key Themes or Topics Mentioned**: \n",
            "   - Disappointment with product quality\n",
            "   - High price vs. low value\n",
            "   - Additional repair costs\n",
            "   - Malfunctioning camera\n",
            "   - Desire for a refund and apology\n",
            "   - Warning to other potential buyers\n",
            "3. **Specific Features or Products Mentioned**: \n",
            "   - XUI890 (mobile phone)\n",
            "   - Battery replacement (cost of $275)\n",
            "   - Camera malfunction (repair cost described as astronomical)\n",
            "### Theme 1: Product Quality\n",
            "\n",
            "1. **Overall Sentiment**: Negative\n",
            "   - Customers express disappointment with the quality of the XUI890 mobile phone, indicating that it does not meet their expectations.\n",
            "\n",
            "2. **Specific Issues Mentioned**:\n",
            "   - Malfunctioning camera\n",
            "   - High repair costs associated with product issues\n",
            "   - General dissatisfaction with the product's performance\n",
            "\n",
            "3. **Recommendations for Improvement**:\n",
            "   - Conduct a thorough quality assurance review of the XUI890 to identify and rectify common issues, particularly with the camera.\n",
            "   - Implement a more robust testing phase before product launches to ensure reliability.\n",
            "   - Consider offering a warranty extension or a satisfaction guarantee to reassure customers about product quality.\n",
            "\n",
            "4. **Prioritization**:\n",
            "   - High Impact, Medium Effort: Quality assurance review and testing improvements.\n",
            "   - Medium Impact, Low Effort: Warranty extension or satisfaction guarantee.\n",
            "\n",
            "---\n",
            "\n",
            "### Theme 2: Price vs. Value\n",
            "\n",
            "1. **Overall Sentiment**: Negative\n",
            "   - Customers feel that the price of the XUI890 is not justified by its performance and features.\n",
            "\n",
            "2. **Specific Issues Mentioned**:\n",
            "   - High price point compared to perceived low value.\n",
            "   - Customers feel they are not getting their money's worth.\n",
            "\n",
            "3. **Recommendations for Improvement**:\n",
            "   - Reassess the pricing strategy for the XUI890, considering a price reduction or promotional offers to enhance perceived value.\n",
            "   - Enhance marketing efforts to better communicate the unique features and benefits of the XUI890 that justify its price.\n",
            "\n",
            "4. **Prioritization**:\n",
            "   - High Impact, Medium Effort: Reassessing pricing strategy.\n",
            "   - Medium Impact, Medium Effort: Enhanced marketing efforts.\n",
            "\n",
            "---\n",
            "\n",
            "### Theme 3: Repair Costs\n",
            "\n",
            "1. **Overall Sentiment**: Negative\n",
            "   - Customers are frustrated with the high costs associated with repairs, particularly for the battery and camera.\n",
            "\n",
            "2. **Specific Issues Mentioned**:\n",
            "   - Battery replacement cost of $275.\n",
            "   - Descriptions of repair costs as \"astronomical.\"\n",
            "\n",
            "3. **Recommendations for Improvement**:\n",
            "   - Review and potentially lower repair costs for common issues, or offer a more affordable repair plan.\n",
            "   - Provide clear information on repair options and costs upfront to manage customer expectations.\n",
            "\n",
            "4. **Prioritization**:\n",
            "   - High Impact, High Effort: Review and adjust repair costs.\n",
            "   - Medium Impact, Low Effort: Improve communication regarding repair options.\n",
            "\n",
            "---\n",
            "\n",
            "### Theme 4: Customer Service and Support\n",
            "\n",
            "1. **Overall Sentiment**: Negative\n",
            "   - Customers express a desire for better support, including refunds and apologies for their negative experiences.\n",
            "\n",
            "2. **Specific Issues Mentioned**:\n",
            "   - Requests for refunds.\n",
            "   - Desire for an apology from the company.\n",
            "\n",
            "3. **Recommendations for Improvement**:\n",
            "   - Establish a more responsive customer service protocol to address complaints and refund requests promptly.\n",
            "   - Train customer service representatives to handle complaints empathetically and offer apologies where appropriate.\n",
            "\n",
            "4. **Prioritization**:\n",
            "   - High Impact, Medium Effort: Improve customer service response times and protocols.\n",
            "   - Medium Impact, Low Effort: Training for customer service representatives on empathy and communication.\n",
            "\n",
            "---\n",
            "\n",
            "### Summary of Prioritized Actions:\n",
            "1. Conduct a quality assurance review of the XUI890 (High Impact, Medium Effort).\n",
            "2. Reassess pricing strategy for the XUI890 (High Impact, Medium Effort).\n",
            "3. Review and adjust repair costs (High Impact, High Effort).\n",
            "4. Improve customer service response times and protocols (High Impact, Medium Effort).\n",
            "5. Enhance marketing efforts to communicate product value (Medium Impact, Medium Effort).\n",
            "6. Improve communication regarding repair options (Medium Impact, Low Effort).\n",
            "7. Train customer service representatives on empathy and communication (Medium Impact, Low Effort).\n",
            "1. The increase in annual revenue in 2022 compared to 2021 was $27.64 billion.\n",
            "\n",
            "2. In 2022, the company experienced a revenue growth of $27.64 billion compared to the previous year.\n",
            "\n",
            "3. The total revenue for 2022 rose by $27.64 billion when compared to the revenue figures from 2021.\n",
            "Final Answer: The increase in annual revenue in 2022 compared to 2021 was $27.64 billion.\n",
            "How much did the annual revenue increase in 2022 when compared to the revenue figures from 2021?\n",
            "Final Answer: The increase in annual revenue in 2022 compared to 2021 was $27.64 billion.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Copy of prompt_engineering_fundamentals_azure_openai.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1nWLG_EmnjJ_PaSK78r0yEH2eUOv99otx\n",
        "\n",
        "# Learning Objectives\n",
        "\n",
        "1. Understand the parameters available to control text generation from LLM APIs.\n",
        "\n",
        "2. Implement key prompt engineering patterns, that is, few-shot, chain-of-thought, rephrase & respond, self-consistency, tree-of-thought & LLM-as-a-judge.\n",
        "\n",
        "# Setup\n",
        "\n",
        "Azure provides seamless integration with the OpenAI API to provide access to the GPT-series of models.\n",
        "\"\"\"\n",
        "\n",
        "!pip install \\\n",
        "  \"openai~=1.107.0\" \\\n",
        "  \"google~=2.0.3\" \\\n",
        "  \"requests~=2.32.4\" \\\n",
        "  \"tqdm~=4.67.1\" \\\n",
        "  \"packaging~=25.0\" \\\n",
        "  \"typing_extensions~=4.15.0\" \\\n",
        "  \"pydantic~=2.11.7\" \\\n",
        "  \"google-api-core~=2.25.1\" \\\n",
        "  \"google-auth~=2.38.0\" \\\n",
        "  \"google-cloud-core~=2.4.3\" \\\n",
        "  \"google-cloud-storage~=2.19.0\"\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "azure_api_key = userdata.get('azure_api_key')\n",
        "azure_endpoint = \"https://sachin1184-2753-gldemo-resource.openai.azure.com/\"\n",
        "api_version = \"2024-06-01\"\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = azure_endpoint,\n",
        "  api_key=azure_api_key,\n",
        "  api_version=api_version\n",
        ")\n",
        "\n",
        "model_name = 'gpt-4o-mini' # deployment name\n",
        "\n",
        "\"\"\"# Prompt Structure\n",
        "\n",
        "Prompts presented to the Azure Open AI API for inference have to follow a specific structure with three roles - `system/developer`, `user` and `assistant`.\n",
        "\n",
        "These roles are:\n",
        "\n",
        "- `system/developer`: A set of instructions specified for the LLM to follow, as outlined by the application developer. The Open AI API considers the terms `system` and `developer` interchangeable, with `developer` being the preferred term for future use. Going forward Open AI will reserve the `system` keyword for additional instructions Open AI might insert into the prompt for better performance (as of now this is not a rigid rule).\n",
        "- `user`: A placeholder for users (i.e., end-users of the application) to present their input\n",
        "- `assistant`: Response from the LLM where the system message is applied to the user input.\n",
        "\n",
        "LLMs are tuned to understand sets of instructions as defined by these roles. LLM APIs provide a mechanism to encapsulate the *constant* portion of these instructions as the *system prompt*. While it is is optional, when a system prompt (e.g., \"Classify the sentiment of the input sentence. Do not answer any other question\") is mentioned, it is automatically pasted ahead of all the instructions entered by the user without us needing to explictly append it with every instruction.\n",
        "\n",
        "System/Developer messages are a great way to restrict the behaviour of the LLM to a specific, controlled set of instructions. Since end-users of the application have no access to the developer message (and can be edited by only the application developer), there is very less chance of the application being hijacked beyond its intended purpose.\n",
        "\n",
        "The `user` and `assistant` roles enable:\n",
        "- multi-turn conversations\n",
        "- showcasing ideal responses expected from the model\n",
        "\n",
        "A typical prompt structure is presented in the figure below.\n",
        "\n",
        "Each example is a pair of `user` and `assistant` messages that illustrates expected output from the LLM.\n",
        "\n",
        "Let us see these roles in action.\n",
        "\"\"\"\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an assistant to a hospital administration team working on extracting important information from medical notes made by doctors.\n",
        "Medical notes will be presented to you in the user input.\n",
        "Extract relevant information as mentioned below in a json format with the following schema.\n",
        "- age: integer, age of the patient\n",
        "- gender: string, can be one of male, female or other\n",
        "- diagnosis: string, can be one of migraine, diabetes, arthritis and acne\n",
        "- weight: integer, weight of the patient\n",
        "- smoking: string, can be one of yes or no\n",
        "\"\"\"\n",
        "\n",
        "user_input = \"\"\"\n",
        "Medical Notes:\n",
        "---\n",
        "A 35-year-old male patient, Mr. Nags, presented with symptoms\n",
        "of increased thirst, frequent urination, fatigue, and unexplained\n",
        "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
        "confirmed by elevated blood sugar levels. Mr. Nags' weight\n",
        "is 80 kgs. He has been prescribed Metformin to be taken twice daily\n",
        "with meals. It was noted during the consultation that the patient is\n",
        "a current smoker.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "user_input = \"\"\"\n",
        "Medical Notes:\n",
        "---\n",
        "Patient Name: Ms. Krishnaveni\n",
        "Age: 45 years\n",
        "Gender: Female\n",
        "\n",
        "Chief Complaint:\n",
        "Ms. Krishnaveni presented with complaints of persistent abdominal pain, bloating, and changes in bowel habits over the past two months.\n",
        "\n",
        "History of Present Illness:\n",
        "Ms. Krishnaveni reports experiencing intermittent abdominal pain, predominantly in the lower abdomen, accompanied by bloating and alternating episodes of diarrhea and constipation. She describes the pain as crampy in nature, relieved partially by defecation but worsening after meals. There is no association with specific food items. She denies any rectal bleeding, unintended weight loss, or fever.\n",
        "\n",
        "Past Medical History:\n",
        "Ms. Krishnaveni has a history of irritable bowel syndrome (IBS), diagnosed five years ago, managed with dietary modifications and occasional use of over-the-counter antispasmodics.\n",
        "\n",
        "Medications:\n",
        "She occasionally takes over-the-counter antispasmodics for symptomatic relief of abdominal discomfort related to IBS.\n",
        "\n",
        "Family History:\n",
        "There is no significant family history of gastrointestinal disorders or malignancies.\n",
        "\n",
        "Social History:\n",
        "Ms. Krishnaveni is a non-smoker and does not consume alcohol. She works as a teacher in a local school.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"# Prompt Parameters\n",
        "\n",
        "## Maximum tokens\n",
        "\n",
        "The parameter (`max_tokens`) refers to the maximum number of tokens that can be generated in the chat completion. With this parameter, we can modify the output length like so:\n",
        "\"\"\"\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an assistant to the marketing team for the gaming company Razer tasked to create advertising content for the company.\n",
        "You will be presented with product information in the input.\n",
        "With this information, write a sleek \"About this item\" description that will be used on its Amazon product page.\n",
        "Use bullet points to delineate key features mentioned in the description.\n",
        "\"\"\"\n",
        "\n",
        "user_input = \"\"\"\n",
        "Below is the metadata about the Razer Ornata V3 X gaming keyboard:\n",
        "Brand: Razer\n",
        "Series: Ornata V3 X\n",
        "Item model number: RZ03-04470200-R3U1\n",
        "Hardware Platform: PC\n",
        "Operating System: Microsoft Windows\n",
        "Item Weight: 2.97 pounds\n",
        "Product Dimensions: 17.46 x 5.68 x 1.23 inches\n",
        "Item Dimensions LxWxH: 17.46 x 5.68 x 1.23 inches\n",
        "Color: Classic Black\n",
        "Manufacturer: Razer\n",
        "Language: English\n",
        "ASIN: B09X6GJ691\n",
        "Special Features: Low-Profile Keys, Spill Resistant, Ergonomic Wrist Rest, Chroma RGB Lighting, Silent Membrane Switches, Cable Routing Options\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ],\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"## Temperature\"\"\"\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an assistant to the marketing team for the gaming company Razer tasked to create advertising content for the company.\n",
        "You will be presented with product information in the input.\n",
        "With this information, write a sleek \"About this item\" description that will be used on its Amazon product page.\n",
        "Use bullet points to delineate key features mentioned in the description.\n",
        "\"\"\"\n",
        "\n",
        "user_input = \"\"\"\n",
        "Below is the metadata about the Razer Ornata V3 X gaming keyboard:\n",
        "Brand: Razer\n",
        "Series: Ornata V3 X\n",
        "Item model number: RZ03-04470200-R3U1\n",
        "Hardware Platform: PC\n",
        "Operating System: Microsoft Windows\n",
        "Item Weight: 2.97 pounds\n",
        "Product Dimensions: 17.46 x 5.68 x 1.23 inches\n",
        "Item Dimensions LxWxH: 17.46 x 5.68 x 1.23 inches\n",
        "Color: Classic Black\n",
        "Manufacturer: Razer\n",
        "Language: English\n",
        "ASIN: B09X6GJ691\n",
        "Special Features: Low-Profile Keys, Spill Resistant, Ergonomic Wrist Rest, Chroma RGB Lighting, Silent Membrane Switches, Cable Routing Options\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ],\n",
        "    temperature=0.4,\n",
        "    max_tokens=256,\n",
        "    n=2\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "print(response.choices[1].message.content)\n",
        "\n",
        "\"\"\"Reducing the temperature reduces variability in generation.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=256,\n",
        "    n=2\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "print(response.choices[1].message.content)\n",
        "\n",
        "\"\"\"# Structuring Prompts\n",
        "\n",
        "## Few-shot prompting\n",
        "\n",
        "While system/developer messages could be used to control the behaviour of LLMs, they become quickly unwieldy when we expect the output to follow a specific format (e.g., JSON). In such situations, few examples go a long way in specifying the behavior of the LLM (i.e., *show, rather than tell*). This technique is referred to as few-shot prompting.\n",
        "\n",
        "Few shot prompt relies on assembling exemplars that specify the output format from the LLM. These exemplars could represent text-to-label tasks or text-to-text tasks.\n",
        "\n",
        "Remember, that these examples are only for illustration of format; the LLM is in inference mode and does not adapt its internal representation based on these examples.\n",
        "\n",
        "Let us now implement a few-shot prompt in code. While we will task the LLM to execute sentiment analysis, we will force the model to follow a specific output format. Instead of describing the format in a system message, we will show the format in action as a set of two examples of assistant responses.\n",
        "\"\"\"\n",
        "\n",
        "few_shot_system_message = \"\"\"\n",
        "You are a product marketer tasked to classify customer reviews in the input as positive or negative in sentiment.\n",
        "Do not explain your answer.\n",
        "Present your output in the following format:\n",
        "{'sentiment': <'positive' or 'negative'>}\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Notice how the system message focuses solely on the task. It mentions that the reviews will be presented in the user input.\"\"\"\n",
        "\n",
        "user_input_example1 = \"\"\"\n",
        "Review:\n",
        "I couldn't be happier with my experience at your store!\n",
        "The staff went above and beyond to assist me, providing exceptional customer service.\n",
        "They were friendly, knowledgeable, and genuinely eager to help.\n",
        "The product I purchased exceeded my expectations and was exactly what I was looking for.\n",
        "From start to finish, everything was seamless and enjoyable.\n",
        "I will definitely be returning and recommending your store to all my friends and family.\n",
        "Thank you for making my shopping experience so wonderful!\n",
        "\"\"\"\n",
        "\n",
        "assistant_output_example1 = \"{'sentiment': 'positive'}\"\n",
        "\n",
        "\"\"\"Notice how we want the output to follow a specific format, that is, a dictionary-like data structure.\"\"\"\n",
        "\n",
        "user_input_example2 = \"\"\"\"\n",
        "Review:\n",
        "I am extremely disappointed with the service I received at your store!\n",
        "The staff was rude and unhelpful, showing no regard for my concerns.\n",
        "Not only did they ignore my requests for assistance, but they also had the audacity to speak to me condescendingly.\n",
        "It's clear that your company values profit over customer satisfaction.\n",
        "I will never shop here again and will make sure to spread the word about my awful experience.\n",
        "You've lost a loyal customer, and I hope others steer clear of your establishment!\n",
        "\"\"\"\n",
        "\n",
        "assistant_output_example2 = \"{'sentiment': 'negative'}\"\n",
        "\n",
        "new_user_input = \"\"\"\n",
        "Review:\n",
        "The layout of the store was well-thought-out, with clear signage and organized aisles that made it easy to navigate.\n",
        "I appreciated the strategic placement of product categories, which not only facilitated a smooth shopping experience but also made it effortless to find exactly what I was looking for.\n",
        "The store's cleanliness and neat displays added to the overall appeal, creating an aesthetically pleasing environment.\n",
        "\"\"\"\n",
        "\n",
        "few_shot_prompt = [\n",
        "        {\"role\": \"developer\", \"content\": few_shot_system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input_example1},\n",
        "        {\"role\": \"assistant\", \"content\": assistant_output_example1},\n",
        "        {\"role\": \"user\", \"content\": user_input_example2},\n",
        "        {\"role\": \"assistant\", \"content\": assistant_output_example2},\n",
        "        {\"role\": \"user\", \"content\": new_user_input}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=few_shot_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"To reiterate, the model does not \"learn\" from the content of the examples. It simply learns the format of the input and output. To verify this, let us swap labels of the examples.\"\"\"\n",
        "\n",
        "few_shot_prompt = [\n",
        "        {\"role\": \"developer\", \"content\": few_shot_system_message},\n",
        "        {\"role\": \"user\", \"content\": user_input_example1},\n",
        "        {\"role\": \"assistant\", \"content\": assistant_output_example2},\n",
        "        {\"role\": \"user\", \"content\": user_input_example2},\n",
        "        {\"role\": \"assistant\", \"content\": assistant_output_example1},\n",
        "        {\"role\": \"user\", \"content\": new_user_input}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=few_shot_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"As the above output indicates, the model does not change its answer.\n",
        "\n",
        "Finally, a simpler variant of few-shot prompting where no examples are provided is called zero-shot prompting. Here is a zero-shot prompt in action.\n",
        "\"\"\"\n",
        "\n",
        "zero_shot_system_message = \"\"\"\n",
        "You are a product marketer tasked to classify customer reviews in the input as positive or negative in sentiment.\n",
        "Do not explain your answer.\n",
        "Present your output in the following format:\n",
        "{'sentiment': <'positive' or 'negative'>}\n",
        "\"\"\"\n",
        "\n",
        "new_user_input = \"\"\"\n",
        "Review:\n",
        "The layout of the store was well-thought-out, with clear signage and organized aisles that made it easy to navigate.\n",
        "I appreciated the strategic placement of product categories, which not only facilitated a smooth shopping experience but also made it effortless to find exactly what I was looking for.\n",
        "The store's cleanliness and neat displays added to the overall appeal, creating an aesthetically pleasing environment.\n",
        "\"\"\"\n",
        "\n",
        "zero_shot_prompt = [\n",
        "        {\"role\": \"developer\", \"content\": zero_shot_system_message},\n",
        "        {\"role\": \"user\", \"content\": new_user_input}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=zero_shot_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"## Chain-of-Thought (CoT) prompting\n",
        "\n",
        "Chain-of-Thought prompting is a technique used in generative AI tasks to guide the model's response generation by providing a sequence of related prompts or questions. Instead of a single prompt, a CoT consists of multiple interconnected steps that build upon each other to guide the model's thinking process. These steps represent the \"thinking\" process that we want the model to follow.\n",
        "\n",
        "The purpose of CoT prompting is to encourage the model to generate more coherent and contextually relevant responses by guiding its thought process in a structured manner. Each step in the chain serves as a stepping stone, providing additional context or constraints for the model to consider while generating the response.\n",
        "\n",
        "CoT prompts could also be augmented with few-shot examples, so that the prompt guides the reasoning power of the model while examples guide expected output.\n",
        "\n",
        "Let us now implement a chain-of-thought prompt for entity extraction. Let us begin by writing a system message that outlines clearly the expected\n",
        "\"\"\"\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an assistant that helps a customer service representatives from a mobile phone company to better understand customer complaints.\n",
        "For each complaint, extract the following information and present it only in a JSON format:\n",
        "1. phone_model: This is the name of the phone - if unknown, just say “UNKNOWN”\n",
        "2. phone_price: The price in dollars - if unknown, assume it to be 1000 $\n",
        "3. complaint_desc: A short description/summary of the complaint in less than 20 words\n",
        "4. additional_charges: How much in dollars did the customer spend to fix the problem? - this should be an integer\n",
        "5. refund_expected: TRUE or FALSE - check if the customer explicitly mentioned the word “refund” to tag as TRUE. If unknown, assume that the customer is not expecting a refund\n",
        "\n",
        "Take a step-by-step approach in your response, before sharing your final answer in the following JSON format:\n",
        "{\n",
        "    phone_model: ,\n",
        "    phone_price: ,\n",
        "    complaint_desc:\n",
        ",\n",
        "    additional_charges: ,\n",
        "    refund_expected:\n",
        "}\n",
        "\n",
        "Explain your reasoning before presenting the final answer.\n",
        "\"\"\"\n",
        "\n",
        "customer_complaint = \"\"\"\n",
        "I am fuming with anger and regret over my purchase of the XUI890.\n",
        "First, the price tag itself was exorbitant at 1500 $, making me expect exceptional quality.\n",
        "Instead, it turned out to be a colossal disappointment.\n",
        "The additional charges to fix its constant glitches and defects drained my wallet even more.\n",
        "I spend 275 $ to get a new battery.\n",
        "The final straw was when the phone's camera malfunctioned, and the repair cost was astronomical.\n",
        "I demand a full refund and an apology for this abysmal product.\n",
        "Returning it would be a relief, as this phone has become nothing but a money pit. Beware, fellow buyers!\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = [\n",
        "        {\"role\": \"developer\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": customer_complaint}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=cot_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"## Prompt Chaining\"\"\"\n",
        "\n",
        "customer_complaint = \"\"\"\n",
        "I am fuming with anger and regret over my purchase of the XUI890.\n",
        "First, the price tag itself was exorbitant at 1500 $, making me expect exceptional quality.\n",
        "Instead, it turned out to be a colossal disappointment.\n",
        "The additional charges to fix its constant glitches and defects drained my wallet even more.\n",
        "I spend 275 $ to get a new battery.\n",
        "The final straw was when the phone's camera malfunctioned, and the repair cost was astronomical.\n",
        "I demand a full refund and an apology for this abysmal product.\n",
        "Returning it would be a relief, as this phone has become nothing but a money pit. Beware, fellow buyers!\n",
        "\"\"\"\n",
        "\n",
        "system_message1 = \"\"\"\n",
        "You are an assistant that helps a customer service representatives from a mobile phone company to better understand customer feedback.\n",
        "Analyze the customer feedback presented in the input and extract key sentiments and themes.\n",
        "For each piece of feedback:\n",
        "1. Identify the main sentiment (positive, negative, neutral)\n",
        "2. Extract key themes or topics mentioned\n",
        "3. Note any specific features or products mentioned\n",
        "\"\"\"\n",
        "\n",
        "first_stage_prompt = [\n",
        "    {\"role\": \"developer\", \"content\": system_message1},\n",
        "    {\"role\": \"user\", \"content\": customer_complaint}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=first_stage_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "first_stage_output = response.choices[0].message.content\n",
        "\n",
        "print(first_stage_output)\n",
        "\n",
        "system_message2 = \"\"\"\n",
        "You are an assistant that helps a customer service representatives from a mobile phone company to better understand customer complaints.\n",
        "Based on the structured feedback analysis presented in the input, generate actionable insights and recommendations.\n",
        "For each theme identified:\n",
        "1. Summarize the overall sentiment\n",
        "2. List specific issues or strengths mentioned\n",
        "3. Provide concrete recommendations for improvement\n",
        "4. Prioritize actions based on impact and effort\n",
        "\"\"\"\n",
        "\n",
        "second_stage_prompt = [\n",
        "    {\"role\": \"developer\", \"content\": system_message2},\n",
        "    {\"role\": \"user\", \"content\": first_stage_output}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=second_stage_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "final_output = response.choices[0].message.content\n",
        "\n",
        "print(final_output)\n",
        "\n",
        "\"\"\"## Self-consistency\n",
        "\n",
        "In self-consistency, we generate multiple answers to the same question and pick the answer that is repeated the most across these occurrences. This is particularly valuable for factual questions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "generation_system_message = \"\"\"\n",
        "You are a helpful assistant tasked to answer queries on financial information.\n",
        "The context needed to answer these queries is presented below:\n",
        "\n",
        "---\n",
        "Context:\n",
        "In 2022, we recognized total revenues of $81.46 billion, respectively, representing an increase of $27.64 billion, compared to the prior year.\n",
        "We continue to ramp production, build new manufacturing capacity and expand our operations to enable increased deliveries and deployments of our products and further revenue growth.\n",
        "---\n",
        "\n",
        "You will be presented a question in the input.\n",
        "Using the context above generate 3 distinct answers to the question.\n",
        "Arrange your answers in numbered bullet points.\n",
        "\"\"\"\n",
        "\n",
        "user_message_template = \"\"\"\n",
        "Question:\n",
        "{question}.\n",
        "\"\"\"\n",
        "\n",
        "factual_question = \"What was the increase in annual revenue in 2022 compared to 2021?\"\n",
        "\n",
        "answers_prompt = [\n",
        "    {'role':'developer', 'content': generation_system_message},\n",
        "     {'role': 'user', 'content': user_message_template.format(\n",
        "         question=factual_question\n",
        "         )\n",
        "     }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=answers_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "factual_answers = response.choices[0].message.content\n",
        "\n",
        "print(factual_answers)\n",
        "\n",
        "consistency_system_message = \"\"\"\n",
        "You are a helpful assistant tasked to answer queries on financial information.\n",
        "You will be presented a question and 3 AI generated answers to the question in the user input.\n",
        "Observe the answers mentioned in the input and choose the answer that occurs most.\n",
        "Present only the most frequent solution in the following format.\n",
        "Final Answer:\n",
        "\"\"\"\n",
        "\n",
        "consistency_user_message = \"\"\"\n",
        "Question:\n",
        "{question}.\n",
        "Answers:\n",
        "{answers}.\n",
        "\"\"\"\n",
        "\n",
        "consistency_prompt = [\n",
        "    {'role':'developer', 'content': consistency_system_message},\n",
        "     {'role': 'user', 'content': consistency_user_message.format(\n",
        "         question=factual_question,\n",
        "         answers=factual_answers\n",
        "         )\n",
        "     }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=consistency_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "rephrase_system_message = \"\"\"\n",
        "You are a helpful assistant tasked to answer queries on financial information.\n",
        "\n",
        "The context required for you to answer the queries is presented below:\n",
        "\n",
        "---\n",
        "Context:\n",
        "In 2022, we recognized total revenues of $81.46 billion, respectively, representing an increase of $27.64 billion, compared to the prior year.\n",
        "We continue to ramp production, build new manufacturing capacity and expand our operations to enable increased deliveries and deployments of our products and further revenue growth.\n",
        "---\n",
        "\n",
        "You will be presented with a question in the input.\n",
        "Using the context presented above, rephrase and expand the question to help you do better answering.\n",
        "Maintain all the information in the original question.\n",
        "Please note that you only have to rephrase the question, do not mention the context or answer the question at this point.\n",
        "The context is only presented for your reference.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"An extract from the Tesla 2022 10-K statement that will be used as context for this demonstration.\"\"\"\n",
        "\n",
        "user_message = \"\"\"\n",
        "Question:\n",
        "What was the increase in annual revenue in 2022 compared to 2021?\n",
        "\"\"\"\n",
        "\n",
        "rephrase_prompt = [\n",
        "    {'role':'developer', 'content': rephrase_system_message},\n",
        "    {'role': 'user', 'content': user_message}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=rephrase_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "rephrased_factual_question = response.choices[0].message.content\n",
        "\n",
        "print(rephrased_factual_question)\n",
        "\n",
        "respond_system_message = \"\"\"\n",
        "You are a helpful assistant tasked to answer queries on financial information.\n",
        "\n",
        "The context required for you to answer the queries is presented below:\n",
        "\n",
        "---\n",
        "Context:\n",
        "In 2022, we recognized total revenues of $81.46 billion, respectively, representing an increase of $27.64 billion, compared to the prior year.\n",
        "We continue to ramp production, build new manufacturing capacity and expand our operations to enable increased deliveries and deployments of our products and further revenue growth.\n",
        "---\n",
        "\n",
        "You will be presented with a question and a rephrased variant in the input.\n",
        "Using the context presented above, use your answer for the rephrased question presented above to answer the original question..\n",
        "Present your final answer in the following format.\n",
        "Final Answer:\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"\"\"\n",
        "Original Question:\n",
        "What was the increase in annual revenue in 2022 compared to 2021?\n",
        "\n",
        "Rephrased Question:\n",
        "What was the difference in total revenues between 2022 and 2021, and how much did it increase in 2022 compared to the previous year?\n",
        "\"\"\"\n",
        "\n",
        "response_prompt = [\n",
        "    {'role':'developer', 'content': respond_system_message},\n",
        "    {'role': 'user', 'content': user_message}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=response_prompt,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\"\"\"## LLM-as-a-Judge\n",
        "\n",
        "In this method, we use another LLM to rate the performance of the LLM used in the original task (see figure below for an example in case of summarization). This method of using LLMs to evaluate LLMs is usualy referred to as LLM-as-a-judge. When LLMs are used to evaluate output, the system message should clearly define the rubrics used for evaluation and the key aspects of the output that should be evaluated. The advantage of using LLMs as judges is that we do not need human baselines (that are costly to collect), while writing down the rubrics for assessment is usually an easier task.\n",
        "\"\"\"\n",
        "\n",
        "example_dialogue = \"\"\"\n",
        "Dialogue:\n",
        "#Person1#: Excuse me, could you tell me where physics 403 is? Has it been moved?\n",
        "#Person2#: OK. Let me check on the computer. Err I'm sorry, but it says here that the class was cancelled. You should have got a notice letter about this.\n",
        "#Person1#: What? I never got it.\n",
        "#Person2#: Are you sure? It says on the computer that the letter was sent out to the students a week ago.\n",
        "#Person1#: Really? I should have got it by now. I wonder if I threw it away with all the junk mail by mistake.\n",
        "#Person2#: Well, it does happen. Err let me check something. What's your name?\n",
        "#Person1#: Woodhouse Laura Woodhouse.\n",
        "#Person2#: OK, Woodhouse. Let me see. Ah, it says here we sent it to your apartment on the Center Street.\n",
        "#Person1#: Oh, that's my old apartment. I moved out of there a little while ago.\n",
        "#Person2#: Well, I suppose you haven't changed your mailing address at the administration office.\n",
        "#Person1#: Yeah, I should have changed it in time.\n",
        "\"\"\"\n",
        "\n",
        "example_summary = \"\"\"\n",
        "Summary:\n",
        "Laura Woodhouse finds out physics is canceled but she never received the mail. #Person2# finds her mailing address is her old apartment. Laura thinks she should have changed it in time.\n",
        "\"\"\"\n",
        "\n",
        "rater_system_message = \"\"\"\n",
        "You are tasked with rating AI-generated summaries of dialogues based on the given metric.\n",
        "You will be presented a dialogue and an AI generated summary of the dialogue as the input.\n",
        "In the input, the dialogue will begin with ###Dialogue while the AI generated summary will begin with ###Summary.\n",
        "\n",
        "Evaluation criteria:\n",
        "The task is to judge the extent to which the metric is followed by the summary.\n",
        "1 - The metric is not followed at all\n",
        "2 - The metric is followed only to a limited extent\n",
        "3 - The metric is followed to a good extent\n",
        "4 - The metric is followed mostly\n",
        "5 - The metric is followed completely\n",
        "\n",
        "Metric:\n",
        "Faithfulness – The factual accuracy and verifiability of the information presented in the summary.\n",
        "Every piece of information mentioned in the summary should be directly verifiable, supported, or reasonably inferred from the dialogue.\n",
        "\n",
        "Instructions:\n",
        "1. First write down the steps that are needed to evaluate the summary as per the metric.\n",
        "2. Give a step-by-step explanation if the summary adheres to the metric considering the dialogues as the input.\n",
        "3. Next, evaluate the extent to which the metric is followed.\n",
        "4. Use the previous information to rate the summary using the evaluaton criteria and assign a score.\n",
        "5. Present your evaluation in the following JSON format:\n",
        "{\n",
        "    'step_by_step_explanation': ,\n",
        "    'score':\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "rater_model = 'gpt-4o-mini'\n",
        "\n",
        "\"\"\"Notice how the rubric is clearly defined. Also the metric used to judge the output is clearly delineated. This prompt can be readily adapted to create multiple raters,e ach focusing on one metric.\"\"\"\n",
        "\n",
        "rater_user_message = f\"\"\"\n",
        "###Dialogue\n",
        "{example_dialogue}\n",
        "\n",
        "###Summary\n",
        "{example_summary}\n",
        "\"\"\"\n",
        "\n",
        "rater_prompt = [\n",
        "    {'role': 'developer', 'content': rater_system_message},\n",
        "    {'role': 'user', 'content': rater_user_message}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=rater_model,\n",
        "    messages=rater_prompt\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=6 color=\"blue\">Power Ahead!</font>"
      ],
      "metadata": {
        "id": "lgmoJOGfwp0H"
      }
    }
  ]
}